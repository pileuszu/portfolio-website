[
  {
    "title": "Generation For NLP Project",
    "desc": "A specialized SLM construction project for the Korean CSAT domain, focusing on overcoming data distribution shifts and ensuring generalization performance.",
    "images": [
      "/images/project_title_9.png"
    ],
    "overview": "This project focused on building a Small Language Model (SLM) specialized for the Korean CSAT domain. The goal was to ensure domain-specific performance and resource efficiency, creating a model capable of solving high-difficulty exams comparable to large LLMs.",
    "problem": "Existing Large Language Models (LLMs) often suffer from performance degradation when applied to specific, highly specialized domains like the Korean CSAT due to distribution shifts. Key challenges included severe training-evaluation data mismatch, selection bias from unbalanced question types, and the need for high resource efficiency in inference.",
    "role": "As a core team member, I focused on data engineering, bias mitigation strategies, and model pipeline optimization. I led the analysis of data distribution issues and designed the quantization strategy for efficient deployment.",
    "solution": "- **Distribution Mismatch:** Resolved performance issues by adding external CSAT-like data and optimizing the training curriculum order.\n- **Bias Mitigation:** Addressed selection bias by oversampling under-represented question types and implementing choice shuffling.\n- **Prediction Stability:** Secured stability using Zero-shot Chain-of-Thought (CoT) and a Logits-based ensemble approach.\n- **Optimization:** Overcame resource constraints by applying GPTQ/AWQ quantization to Qwen3-VL and designing a Distributed Sharding pipeline.",
    "learnings": "I learned that in specialized domains, model performance relies more heavily on structural data design and pipeline quality than just model size. I gained the ability to design model optimizations with the final operational environment's constraints in mind.",
    "tech": [
      "Python",
      "Pytorch",
      "Hugging Face",
      "WandB"
    ],
    "year": "2026",
    "type": "team",
    "link": "https://github.com/boostcampaitech8/pro-nlp-generationfornlp-nlp-01"
  },
  {
    "title": "MRC Project",
    "desc": "A 2-stage Open-Domain Question Answering (ODQA) system utilizing a Retriever-Reader architecture to solve information retrieval tasks.",
    "images": [
      "/images/project_title_8.png"
    ],
    "overview": "We constructed a 2-stage Open-Domain Question Answering (ODQA) system utilizing a Retriever-Reader architecture. The project aimed to accurately retrieve information and answer questions from a vast open-domain dataset.",
    "problem": "The system initially faced significant challenges with Reader hallucination, primarily caused by a lack of Negative Passages in training and the Retriever's poor discrimination performance, which led to irrelevant context being fed to the Reader.",
    "role": "I led the data engineering efforts, starting with comprehensive EDA to identify data quality issues. I was responsible for designing the negative sampling strategy to improve the Retriever's discrimination capability.",
    "solution": "- **Unknown Strategy:** Addressed hallucination issues by designing a Hard Negative Sampling strategy and building a high-difficulty wrong answer dataset.\n- **Retrieval Improvement:** Improved Dense Retriever discrimination via Hard Negative Mining and contributed to the design of a BM25 + Dense Hybrid Retrieval system.\n- **Ensemble:** Participated in implementing a Soft Voting ensemble to boost final leaderboard performance.",
    "learnings": "This project taught me that data quality and robust structural design are often more determining factors for performance than simply increasing model complexity. I internalized the value of rigorous EDA in identifying the root causes of model failure.",
    "tech": [
      "Python",
      "Pytorch",
      "Hugging Face",
      "WandB"
    ],
    "year": "2025",
    "type": "team",
    "link": "https://github.com/boostcampaitech8/pro-nlp-mrc-nlp-01"
  },
  {
    "title": "Laftel Watch Together",
    "desc": "A Chrome extension enabling real-time synchronized video watching on Laftel with friends, featuring host control and WebSocket communication.",
    "images": [
      "/images/project_title_7.png"
    ],
    "overview": "'Laftel Watch Together' is a Chrome extension designed to allow users to watch videos on the Laftel streaming platform simultaneously with friends in real-time. It mimics the experience of a 'watch party' remotely.",
    "problem": "Users wanted to watch content together, but simply pressing play at the same time is unreliable. There was a need for a solution that strictly synchronizes playback state (play/pause/seek) across multiple clients with low latency.",
    "role": "I was the sole developer for this project, handling both the Chrome Extension client-side logic and the Node.js WebSocket signaling server.",
    "solution": "- **Synchronization:** Implemented a robust sync system where a designated 'Host' controls the playback flow. Any action by the host is immediately broadcast to all participants.\n- **Real-time Communication:** Utilized WebSockets for low-latency state exchange.\n- **Resilience:** added auto-reconnect functionality to handle network interruptions smoothly.",
    "learnings": "I gained a deep understanding of the Chrome Extension architecture (Manifest V3) and the challenges of real-time state synchronization. I learned how to handle edge cases in network communication to ensure a smooth user experience.",
    "tech": [
      "JavaScript",
      "Node.js",
      "WebSocket",
      "Chrome Extension"
    ],
    "year": "2025",
    "type": "personal",
    "link": "https://github.com/pileuszu/raftel-watch-together"
  },
  {
    "title": "Movie Review Sentiment Analysis",
    "desc": "An NLP classification project categorizing Korean movie reviews into 4 sentiment classes using various BERT-based models and TAPT.",
    "images": [
      "/images/project_title_6.png"
    ],
    "overview": "This NLP project aimed to classify Korean movie reviews into four distinct sentiment classes (Negative, Neutral, Positive, Strong Positive) to analyze public opinion effectively.",
    "problem": "The main challenge was accurately capturing subtle sentiment nuances in Korean text, especially given potential class imbalances and noise in user-generated reviews.",
    "role": "I was responsible for designing the experimental pipeline, conducting fair model comparisons, and verifying validation strategies. I also led the analysis of loss functions.",
    "solution": "- **Fair Comparison:** Conducted controlled experiments on 5 Korean BERT-series models under identical hyperparameters to identify the best base model.\n- **TAPT:** Verified the effectiveness of Task-Adaptive Pre-Training (TAPT) on the specific movie review dataset.\n- **Pipeline:** Designed a preprocessing pipeline focused on preserving sentiment-heavy expressions.",
    "learnings": "I learned that domain-appropriate pre-training and careful data design are core to NLP performance. I also gained an appreciation for analyzing failed experiments (like my Focal Loss attempts) as they provide valuable insights into model behavior.",
    "tech": [
      "Python",
      "Pytorch",
      "Hugging Face",
      "WandB",
      "TAPT"
    ],
    "year": "2025",
    "type": "personal",
    "link": "https://github.com/pileuszu/boostcamp-movie-review-sentiment-analysis"
  },
  {
    "title": "Portfolio Website",
    "desc": "A sleek and modern portfolio website built with TypeScript, React, Next.js, and SCSS.",
    "images": [
      "/images/project_title_5.png"
    ],
    "overview": "This project is a personal portfolio website designed to showcase my projects, skills, and experience in a modern, interactive format.",
    "problem": "I needed a clean, professional online presence to effectively present my work and resume to potential employers.",
    "role": "I designed and developed the entire application from scratch.",
    "solution": "- **Tech Stack:** Built using React 18, Next.js 15, and TypeScript to ensure maintainability.\n- **Styling:** Utilized SCSS modules for a clean and conflict-free styling architecture.",
    "learnings": "I strengthened my proficiency in Next.js App Router and responsive web design practices through this implementation.",
    "tech": [
      "TypeScript",
      "React",
      "Next.js",
      "SCSS"
    ],
    "year": "2025",
    "type": "personal",
    "link": "https://github.com/pileuszu/portfolio-website"
  },
  {
    "title": "ChzzkStreamDeck",
    "desc": "A comprehensive streaming widget system for OBS Studio with real-time chat overlay, Spotify integration, and music bot functionality.",
    "images": [
      "/images/project_title_4.png"
    ],
    "overview": "ChzzkStreamDeck is a comprehensive streaming widget system integrating OBS Studio with the CHZZK streaming platform, providing chat overlays and music controls.",
    "problem": "Streamers often struggle to manage multiple disparate tools for chat, music, and alerts. There was a need for a unified dashboard that integrates these services seamlessly into OBS.",
    "role": "I developed the full stack solution, including the Node.js backend for API integration and the frontend dashboard for user control.",
    "solution": "- **Real-time Overlay:** Implemented a chat overlay using Server-Sent Events (SSE) that supports CHZZK emoticons.\n- **Integrations:** Integrated Spotify API via OAuth 2.0 for music control and built a server-based chat bot for music queue management.\n- **Architecture:** Designed a modular architecture that cleanly separates chat, music, and bot functionalities.",
    "learnings": "I gained significant expertise in WebSocket/SSE for real-time data streaming, OAuth 2.0 authentication flows, and integrating third-party APIs into a unified service ecosystem.",
    "tech": [
      "Node.js",
      "JavaScript",
      "CSS",
      "Chzzk API",
      "Spotify API"
    ],
    "year": "2025",
    "type": "personal",
    "link": "https://github.com/pileuszu/ChzzkStreamDeck"
  },
  {
    "title": "3D Train Simulator",
    "desc": "A real-time 3D train simulator built with WebGL and JavaScript, featuring customizable camera controls and track configurations",
    "images": [
      "/images/project_title_3.png"
    ],
    "overview": "This project is a real-time 3D train simulator running directly in the web browser, allowing users to drive a train and customize tracks.",
    "problem": "The challenge was to create a performant, interactive 3D simulation using raw WebGL and JavaScript, without relying on heavy game engines, to understand the fundamentals of 3D graphics.",
    "role": "I focused on the graphics programming aspects, including 3D rendering, hierarchy management, and performance optimization.",
    "solution": "- **Rendering:** Implemented 3D modeling with hierarchical structures and tree-based traversal for the train components.\n- **Customization:** Developed a dynamic track generation system using an intuitive CSV-like syntax.\n- **Optimization:** Implemented conditional re-rendering and FPS limiting to ensure smooth performance in the browser.",
    "learnings": "I deepened my understanding of the 3D graphics pipeline, including matrix transformations, shader programming (GLSL), and texture mapping. I learned how to optimize rendering loops for web applications.",
    "tech": [
      "WebGL",
      "glMatrix",
      "JavaScript"
    ],
    "year": "2025",
    "type": "personal",
    "link": "https://pileuszu.github.io/study-webgl-train-simulation/"
  },
  {
    "title": "Prediction of Pregnancy Success",
    "desc": "A machine learning model achieving 0.7347 accuracy in predicting pregnancy success rates for infertility patients using IVF and DI treatment data",
    "images": [
      "/images/project_title_2.png"
    ],
    "overview": "This research project involved developing a machine learning model to predict pregnancy success rates for infertility patients, aiming to assist in clinical decision-making.",
    "problem": "Predicting success rates for IVF and DI treatments is highly complex due to the multitude of biological factors involved (e.g., patient age, medical history, ovulation data). High prediction accuracy is crucial for optimizing treatment plans.",
    "role": "I acted as the sole researcher and developer, responsible for all stages from data preprocessing to model evaluation.",
    "solution": "- **Targeted Modeling:** Built separate, optimized models for IVF and DI treatments to handle their distinct characteristics.\n- **Feature Engineering:** Performed extensive analysis on patient data to identify key predictors.\n- **Ensemble:** Utilized ensemble techniques to combine model strengths, achieving a final accuracy of 0.7347.",
    "learnings": "This project provided practical experience in applying machine learning to sensitive healthcare data. I learned how to deal with real-world data noise and the importance of domain-specific feature engineering in medical AI.",
    "tech": [
      "Python",
      "Scikit-learn",
      "Pandas",
      "NumPy",
      "Machine Learning"
    ],
    "year": "2025",
    "type": "personal",
    "link": "https://github.com/pileuszu/dacon-infertility-treatment-prediction"
  },
  {
    "title": "SSALON",
    "desc": "A web service providing one-time gathering communities based on 'Interactive 3D Badge Cards'",
    "images": [
      "/images/project_title_1.png"
    ],
    "overview": "SSALON is a web platform for one-time social gatherings where user interaction centers around interactive 3D Badge Cards.",
    "problem": "Traditional event platforms often lack engaging, interactive elements for profile representation. We wanted to create a unique way for users to showcase their identity and achievements.",
    "role": "I was responsible for the backend architecture using Express.js and the implementation of 3D interactive elements using Three.js.",
    "solution": "- **3D Interaction:** Developed interactive 3D badge cards with mouse-tracking effects using Three.js.\n- **Backend:** Built a robust REST API with Express.js to handle user data, badge collection, and event management.\n- **Database:** utilized MySQL/MariaDB for structured data storage.",
    "learnings": "I learned the intricacies of integrating 3D graphics into a standard web interface and managing the performance implications. I also gained experience in designing scalable database schemas for social platforms.",
    "tech": [
      "React",
      "Three.js",
      "Express.js",
      "MariaDB"
    ],
    "year": "2024",
    "type": "team",
    "link": "https://github.com/lee1684/SKYTeam"
  }
]